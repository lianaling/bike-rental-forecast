{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks for Regression\n",
    "\n",
    "_By: Ling Li Ya, Liana_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/liana/.local/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (59.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/liana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/liana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/liana/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/liana/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras in /home/liana/.local/lib/python3.8/site-packages (2.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned dataset with no outliers\n",
    "X_train_no = pd.read_csv('../dataset/no_outliers/X_train.csv')\n",
    "X_test_no = pd.read_csv('../dataset/no_outliers/X_test.csv')\n",
    "y_train_no = pd.read_csv('../dataset/no_outliers/y_train.csv')\n",
    "y_test_no = pd.read_csv('../dataset/no_outliers/y_test.csv')\n",
    "\n",
    "# Uncleaned original data\n",
    "X_train_with = pd.read_csv('../dataset/with_outliers/X_train.csv')\n",
    "X_test_with = pd.read_csv('../dataset/with_outliers/X_test.csv')\n",
    "y_train_with = pd.read_csv('../dataset/with_outliers/y_train.csv')\n",
    "y_test_with = pd.read_csv('../dataset/with_outliers/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 9) (578, 1) (145, 9) (145, 1)\n"
     ]
    }
   ],
   "source": [
    "def standardise_data(X_train, y_train, X_test, y_test):\n",
    "    X_scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # Scale data to standardise data values\n",
    "    X_train_trans = X_scaler.fit_transform(X_train)\n",
    "    y_train_trans = y_scaler.fit_transform(y_train)\n",
    "    X_test_trans = X_scaler.transform(X_test)\n",
    "    y_test_trans = y_scaler.transform(y_test)\n",
    "    \n",
    "    print(X_train_trans.shape, y_train_trans.shape, X_test_trans.shape, y_test_trans.shape)\n",
    "\n",
    "    return X_scaler, y_scaler, X_train_trans, y_train_trans, X_test_trans, y_test_trans\n",
    "\n",
    "X_scaler_no, y_scaler_no, X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans = standardise_data(X_train_no, y_train_no, X_test_no, y_test_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Using a layer with 5 neurons, with 9 input dimensions of normal weight, using relu activation function. Batch size is 20 and training epochs are 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.9996 - mse: 0.9996 - mae: 0.8138\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.9928 - mse: 0.9928 - mae: 0.8109\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 937us/step - loss: 0.9580 - mse: 0.9580 - mae: 0.7961\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 823us/step - loss: 0.8489 - mse: 0.8489 - mae: 0.7473\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 875us/step - loss: 0.6563 - mse: 0.6563 - mae: 0.6553\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 929us/step - loss: 0.4537 - mse: 0.4537 - mae: 0.5435\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 770us/step - loss: 0.3144 - mse: 0.3144 - mae: 0.4495\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 906us/step - loss: 0.2486 - mse: 0.2486 - mae: 0.3933\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 806us/step - loss: 0.2230 - mse: 0.2230 - mae: 0.3639\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 928us/step - loss: 0.2108 - mse: 0.2108 - mae: 0.3493\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 875us/step - loss: 0.2018 - mse: 0.2018 - mae: 0.3402\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 867us/step - loss: 0.1954 - mse: 0.1954 - mae: 0.3338\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.1888 - mse: 0.1888 - mae: 0.3284\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 930us/step - loss: 0.1843 - mse: 0.1843 - mae: 0.3243\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 874us/step - loss: 0.1793 - mse: 0.1793 - mae: 0.3191\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 865us/step - loss: 0.1752 - mse: 0.1752 - mae: 0.3161\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 928us/step - loss: 0.1711 - mse: 0.1711 - mae: 0.3122\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1671 - mse: 0.1671 - mae: 0.3090\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1641 - mse: 0.1641 - mae: 0.3051\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 840us/step - loss: 0.1602 - mse: 0.1602 - mae: 0.3015\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 922us/step - loss: 0.1579 - mse: 0.1579 - mae: 0.2985\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 883us/step - loss: 0.1568 - mse: 0.1568 - mae: 0.2989\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.1529 - mse: 0.1529 - mae: 0.2931\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 930us/step - loss: 0.1512 - mse: 0.1512 - mae: 0.2908\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.1496 - mse: 0.1496 - mae: 0.2897\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 844us/step - loss: 0.1482 - mse: 0.1482 - mae: 0.2882\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 919us/step - loss: 0.1473 - mse: 0.1473 - mae: 0.2872\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 818us/step - loss: 0.1456 - mse: 0.1456 - mae: 0.2850\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 838us/step - loss: 0.1447 - mse: 0.1447 - mae: 0.2851\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 880us/step - loss: 0.1437 - mse: 0.1437 - mae: 0.2831\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 874us/step - loss: 0.1430 - mse: 0.1430 - mae: 0.2820\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 797us/step - loss: 0.1419 - mse: 0.1419 - mae: 0.2817\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 901us/step - loss: 0.1415 - mse: 0.1415 - mae: 0.2803\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 937us/step - loss: 0.1408 - mse: 0.1408 - mae: 0.2798\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 792us/step - loss: 0.1407 - mse: 0.1407 - mae: 0.2810\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 913us/step - loss: 0.1394 - mse: 0.1394 - mae: 0.2788\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 843us/step - loss: 0.1391 - mse: 0.1391 - mae: 0.2779\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 807us/step - loss: 0.1380 - mse: 0.1380 - mae: 0.2773\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 898us/step - loss: 0.1375 - mse: 0.1375 - mae: 0.2773\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 801us/step - loss: 0.1365 - mse: 0.1365 - mae: 0.2748\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 861us/step - loss: 0.1358 - mse: 0.1358 - mae: 0.2757\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 910us/step - loss: 0.1349 - mse: 0.1349 - mae: 0.2727\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.1336 - mse: 0.1336 - mae: 0.2726\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 807us/step - loss: 0.1328 - mse: 0.1328 - mae: 0.2725\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 867us/step - loss: 0.1322 - mse: 0.1322 - mae: 0.2703\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 877us/step - loss: 0.1321 - mse: 0.1321 - mae: 0.2719\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.1319 - mse: 0.1319 - mae: 0.2675\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 875us/step - loss: 0.1300 - mse: 0.1300 - mae: 0.2697\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.1300 - mse: 0.1300 - mae: 0.2681\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1293 - mse: 0.1293 - mae: 0.2692\n"
     ]
    }
   ],
   "source": [
    "def create_seq_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining the input layer and first hidden layer\n",
    "    model.add(Dense(units=5, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the second layer of the model\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "    # The output neuron is a single fully connected node as only a single number is predicted\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    # Fitting the ANN to the training data\n",
    "    model.fit(X_train, y_train, batch_size=20, epochs=50, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "model_no = create_seq_model()\n",
    "model_no = train_model(model_no, X_train_no_trans, y_train_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "To find the best accuracy with the minimum number of layers/neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Mean Square Error (MSE) is used with the formula `(sum of all (y_true - y_pred)^2)/total number of y_true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Parameters: batch_size: 5 - Epochs: 5 MSE: 0.18868188385425078\n",
      "2 Parameters: batch_size: 5 - Epochs: 10 MSE: 0.1683946006445905\n",
      "3 Parameters: batch_size: 5 - Epochs: 50 MSE: 0.11697317051978914\n",
      "4 Parameters: batch_size: 5 - Epochs: 100 MSE: 0.12777619040696478\n",
      "5 Parameters: batch_size: 10 - Epochs: 5 MSE: 0.32857530275655283\n",
      "6 Parameters: batch_size: 10 - Epochs: 10 MSE: 0.18111057596062158\n",
      "7 Parameters: batch_size: 10 - Epochs: 50 MSE: 0.1574689012836356\n",
      "8 Parameters: batch_size: 10 - Epochs: 100 MSE: 0.11375812369318465\n",
      "9 Parameters: batch_size: 15 - Epochs: 5 MSE: 0.4699701605274497\n",
      "10 Parameters: batch_size: 15 - Epochs: 10 MSE: 0.2056974191721129\n",
      "11 Parameters: batch_size: 15 - Epochs: 50 MSE: 0.13633110362610576\n",
      "12 Parameters: batch_size: 15 - Epochs: 100 MSE: 0.13204566619481575\n",
      "13 Parameters: batch_size: 20 - Epochs: 5 MSE: 0.7736067408150284\n",
      "14 Parameters: batch_size: 20 - Epochs: 10 MSE: 0.5824828585867802\n",
      "15 Parameters: batch_size: 20 - Epochs: 50 MSE: 0.14285528004405834\n",
      "16 Parameters: batch_size: 20 - Epochs: 100 MSE: 0.1438879492129092\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters for ANN\n",
    "def find_best_params(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list = [5, 10, 15, 20]\n",
    "    epoch_list = [5, 10, 50, 100]\n",
    "\n",
    "    results = pd.DataFrame(columns=['trial_num', 'param', 'accuracy'])\n",
    "    \n",
    "    # Initialising the trials\n",
    "    trial_number = 0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            trial_number += 1\n",
    "            # Create ANN model\n",
    "            model = Sequential()\n",
    "\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Output neuron\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            MSE = 0\n",
    "            for i in range(y_test.shape[0]):\n",
    "                MSE += (y_test[i,0] - pred[i][0])**2\n",
    "\n",
    "            MSE /= y_test.shape[0]\n",
    "            \n",
    "            # Printing the results of the current iteration\n",
    "            print(trial_number, 'Parameters:','batch_size:', batch_size_trial,'-', 'Epochs:',epochs_trial, 'MSE:', MSE)\n",
    "            \n",
    "            results = results.append(pd.DataFrame(data=[[trial_number, str(batch_size_trial)+'-'+str(epochs_trial), MSE]], columns=['trial_num', 'param', 'mse'] ))\n",
    "\n",
    "    return(results)\n",
    "\n",
    "results_no = find_best_params(X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_bar_chart(results):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    colors = ['pink' if result != min(results['mse']) else 'purple' for result in results['mse']]\n",
    "    plt.bar(results['param'], height=results['mse'], color=colors)\n",
    "    # plt.axhline(y=1.0, color='purple', linestyle='-')\n",
    "    for a, b in zip([x for x in range(len(results['mse']))], round(results['mse'], 5)):\n",
    "        plt.text(a, b, str(b), color='black')\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_chart(results_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MSE, a lower value is better. From the graph above, it can be known that the best hyperparameters are `batch_size` = 10 and `epochs` = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_data):\n",
    "    # Sum of squared error\n",
    "    test_data['SE'] = (test_data['count'] - test_data['pred_count'])**2\n",
    "    r2 = r2_score(test_data['count'], test_data['pred_count'])\n",
    "\n",
    "    print(test_data.head())\n",
    "\n",
    "    print(\"r2: \", r2)\n",
    "    print(\"MSE: \", np.mean(test_data['SE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season      year     month  holiday   weekday   weather  temperature  \\\n",
      "0  0.449189  1.003466  0.147272 -0.16873 -1.505757 -0.736674     1.234309   \n",
      "1 -0.461798  1.003466 -0.439786 -0.16873  0.493847 -0.736674     0.533490   \n",
      "2  0.449189  1.003466  0.440802 -0.16873  0.993748  1.090784     1.475494   \n",
      "3 -0.461798  1.003466 -0.733315 -0.16873  0.993748 -0.736674    -0.504081   \n",
      "4  1.360175  1.003466  1.321389 -0.16873 -1.005856 -0.736674    -0.963703   \n",
      "\n",
      "   humidity  windspeed     count  pred_count        SE  \n",
      "0 -0.028125  -0.246866  1.095397    1.093887  0.000002  \n",
      "1 -0.761407   0.529099  1.506397    1.486071  0.000413  \n",
      "2  0.104396   0.349382  1.397250    1.041020  0.126899  \n",
      "3 -1.771513   1.460496  1.023851    0.552350  0.222313  \n",
      "4 -0.943989   0.619070  0.396644    0.286113  0.012217  \n",
      "r2:  0.9049814780589727\n",
      "MSE:  0.10847355103362535\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune hyperparameters\n",
    "def fine_tune_model(model, batch_size, epochs, X_scaler, y_scaler, X_train_trans, y_train_trans, X_test_trans, y_test_trans, columns):\n",
    "    model.fit(X_train_trans, y_train_trans, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "    pred = model.predict(X_test_trans)\n",
    "\n",
    "    test_data_scaled = pd.DataFrame(data=X_test_trans, columns=columns)\n",
    "    test_data_scaled['count'] = y_test_trans\n",
    "    test_data_scaled['pred_count'] = pred\n",
    "    evaluate_model(test_data_scaled)\n",
    "\n",
    "    # Scale predictions\n",
    "    pred = y_scaler.inverse_transform(pred)\n",
    "\n",
    "    # Scale back to original\n",
    "    y_test = y_scaler.inverse_transform(y_test_trans)\n",
    "    X_test = X_scaler.inverse_transform(X_test_trans)\n",
    "\n",
    "    test_data = pd.DataFrame(data=X_test, columns=columns)\n",
    "    test_data['count'] = y_test\n",
    "    test_data['pred_count'] = pred\n",
    "    # print(test_data.head())\n",
    "\n",
    "    return test_data\n",
    "\n",
    "test_data_no = fine_tune_model(\n",
    "        model=model_no,\n",
    "        batch_size=10,\n",
    "        epochs=100,\n",
    "        X_scaler=X_scaler_no,\n",
    "        y_scaler=y_scaler_no,\n",
    "        X_train_trans=X_train_no_trans,\n",
    "        y_train_trans=y_train_no_trans,\n",
    "        X_test_trans=X_test_no_trans,\n",
    "        y_test_trans=y_test_no_trans,\n",
    "        columns=X_test_no.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_117 (Dense)           (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Data With Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584, 9) (584, 1) (147, 9) (147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_scaler_with, y_scaler_with, X_train_with_trans, y_train_with_trans, X_test_with_trans, y_test_with_trans = standardise_data(X_train_with, y_train_with, X_test_with, y_test_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.9957 - mse: 0.9957 - mae: 0.8141\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.9747 - mse: 0.9747 - mae: 0.8055\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 992us/step - loss: 0.9106 - mse: 0.9106 - mae: 0.7780\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 916us/step - loss: 0.7709 - mse: 0.7709 - mae: 0.7149\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5765 - mse: 0.5765 - mae: 0.6166\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4034 - mse: 0.4034 - mae: 0.5120\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2918 - mse: 0.2918 - mae: 0.4275\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 981us/step - loss: 0.2382 - mse: 0.2382 - mae: 0.3758\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 841us/step - loss: 0.2140 - mse: 0.2140 - mae: 0.3494\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 799us/step - loss: 0.2024 - mse: 0.2024 - mae: 0.3366\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 852us/step - loss: 0.1936 - mse: 0.1936 - mae: 0.3287\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 940us/step - loss: 0.1854 - mse: 0.1854 - mae: 0.3220\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 801us/step - loss: 0.1783 - mse: 0.1783 - mae: 0.3164\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 989us/step - loss: 0.1720 - mse: 0.1720 - mae: 0.3113\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 865us/step - loss: 0.1650 - mse: 0.1650 - mae: 0.3039\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 968us/step - loss: 0.1598 - mse: 0.1598 - mae: 0.2990\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 791us/step - loss: 0.1552 - mse: 0.1552 - mae: 0.2943\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 875us/step - loss: 0.1509 - mse: 0.1509 - mae: 0.2903\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 895us/step - loss: 0.1475 - mse: 0.1475 - mae: 0.2859\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1442 - mse: 0.1442 - mae: 0.2824\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1408 - mse: 0.1408 - mae: 0.2787\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1384 - mse: 0.1384 - mae: 0.2756\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1364 - mse: 0.1364 - mae: 0.2735\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1350 - mse: 0.1350 - mae: 0.2750\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1327 - mse: 0.1327 - mae: 0.2702\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 982us/step - loss: 0.1306 - mse: 0.1306 - mae: 0.2687\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 952us/step - loss: 0.1291 - mse: 0.1291 - mae: 0.2653\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1278 - mse: 0.1278 - mae: 0.2640\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 952us/step - loss: 0.1270 - mse: 0.1270 - mae: 0.2626\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1256 - mse: 0.1256 - mae: 0.2624\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1243 - mse: 0.1243 - mae: 0.2617\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1234 - mse: 0.1234 - mae: 0.2608\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1230 - mse: 0.1230 - mae: 0.2602\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1225 - mse: 0.1225 - mae: 0.2617\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1216 - mse: 0.1216 - mae: 0.2586\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1214 - mse: 0.1214 - mae: 0.2582\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1205 - mse: 0.1205 - mae: 0.2576\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1199 - mse: 0.1199 - mae: 0.2552\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1197 - mse: 0.1197 - mae: 0.2564\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1196 - mse: 0.1196 - mae: 0.2571\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1186 - mse: 0.1186 - mae: 0.2539\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1189 - mse: 0.1189 - mae: 0.2558\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1186 - mse: 0.1186 - mae: 0.2542\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1179 - mse: 0.1179 - mae: 0.2555\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1177 - mse: 0.1177 - mae: 0.2541\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1171 - mse: 0.1171 - mae: 0.2521\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1165 - mse: 0.1165 - mae: 0.2533\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1175 - mse: 0.1175 - mae: 0.2561\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 917us/step - loss: 0.1176 - mse: 0.1176 - mae: 0.2517\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 979us/step - loss: 0.1161 - mse: 0.1161 - mae: 0.2543\n"
     ]
    }
   ],
   "source": [
    "model_with = create_seq_model()\n",
    "model_with = train_model(model_with, X_train_with_trans, y_train_with_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same `batch_size` and `epochs` are used for accuracy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season      year     month   holiday   weekday   weather  temperature  \\\n",
      "0  0.441688 -0.993174  0.131722 -0.167836  1.508537 -0.720359     1.060122   \n",
      "1  0.441688 -0.993174  0.131722 -0.167836  0.502271 -0.720359     1.404064   \n",
      "2 -1.362130 -0.993174 -1.603446 -0.167836  1.508537  1.141100    -1.401794   \n",
      "3 -1.362130 -0.993174 -1.314251 -0.167836 -0.503995  1.141100    -1.625316   \n",
      "4 -1.362130  1.006873 -1.603446 -0.167836  0.502271  1.141100    -0.813466   \n",
      "\n",
      "   humidity  windspeed     count  pred_count        SE  \n",
      "0 -0.276179   0.246691  0.750388    0.313951  0.190477  \n",
      "1  0.196746  -0.396460  0.050831    0.076471  0.000657  \n",
      "2 -0.891873  -0.412649 -1.706735   -1.424517  0.079647  \n",
      "3  1.469644  -1.783575 -1.647869   -1.818341  0.029061  \n",
      "4  1.041464  -1.519431 -0.220898   -0.254788  0.001149  \n",
      "r2:  0.8852795834404821\n",
      "MSE:  0.13478485437745777\n"
     ]
    }
   ],
   "source": [
    "test_data_with = fine_tune_model(\n",
    "    model=model_with,\n",
    "    batch_size=10,\n",
    "    epochs=100,\n",
    "    X_scaler=X_scaler_with,\n",
    "    y_scaler=y_scaler_with,\n",
    "    X_train_trans=X_train_with_trans,\n",
    "    y_train_trans=y_train_with_trans,\n",
    "    X_test_trans=X_test_with_trans,\n",
    "    y_test_trans=y_test_with_trans,\n",
    "    columns=X_test_with.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_171 (Dense)           (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, using cleaned data without outliers would give a higher accuracy than using data with outliers."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
