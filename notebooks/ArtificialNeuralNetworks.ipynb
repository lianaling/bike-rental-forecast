{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks for Regression\n",
    "\n",
    "_By: Ling Li Ya, Liana_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (58.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: keras in /home/liana/projects/fyp/venv/lib/python3.8/site-packages (2.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 17:42:15.832664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-30 17:42:15.832721: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned dataset with no outliers\n",
    "X_train_no = pd.read_csv('../dataset/no_outliers/X_train.csv')\n",
    "X_test_no = pd.read_csv('../dataset/no_outliers/X_test.csv')\n",
    "y_train_no = pd.read_csv('../dataset/no_outliers/y_train.csv')\n",
    "y_test_no = pd.read_csv('../dataset/no_outliers/y_test.csv')\n",
    "\n",
    "# Uncleaned original data\n",
    "X_train_with = pd.read_csv('../dataset/with_outliers/X_train.csv')\n",
    "X_test_with = pd.read_csv('../dataset/with_outliers/X_test.csv')\n",
    "y_train_with = pd.read_csv('../dataset/with_outliers/y_train.csv')\n",
    "y_test_with = pd.read_csv('../dataset/with_outliers/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 9) (578, 1) (145, 9) (145, 1)\n"
     ]
    }
   ],
   "source": [
    "def standardise_data(X_train, y_train, X_test, y_test):\n",
    "    X_scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # Scale data to standardise data values\n",
    "    X_train_trans = X_scaler.fit_transform(X_train)\n",
    "    y_train_trans = y_scaler.fit_transform(y_train)\n",
    "    X_test_trans = X_scaler.transform(X_test)\n",
    "    y_test_trans = y_scaler.transform(y_test)\n",
    "    \n",
    "    print(X_train_trans.shape, y_train_trans.shape, X_test_trans.shape, y_test_trans.shape)\n",
    "\n",
    "    return X_scaler, y_scaler, X_train_trans, y_train_trans, X_test_trans, y_test_trans\n",
    "\n",
    "X_scaler_no, y_scaler_no, X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans = standardise_data(X_train_no, y_train_no, X_test_no, y_test_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Using a layer with 5 neurons, with 9 input dimensions of normal weight, using relu activation function. Batch size is 20 and training epochs are 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 17:42:21.655027: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2021-11-30 17:42:21.655106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Liana-ASUS): /proc/driver/nvidia/version does not exist\n",
      "2021-11-30 17:42:21.655995: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 1s 6ms/step - loss: 0.9972 - mse: 0.9972 - mae: 0.8129\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.9790 - mse: 0.9790 - mae: 0.8054\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.9168 - mse: 0.9168 - mae: 0.7791\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7792 - mse: 0.7792 - mae: 0.7165\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5830 - mse: 0.5830 - mae: 0.6193\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4095 - mse: 0.4095 - mae: 0.5182\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2983 - mse: 0.2983 - mae: 0.4367\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2454 - mse: 0.2454 - mae: 0.3878\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2223 - mse: 0.2223 - mae: 0.3608\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2097 - mse: 0.2097 - mae: 0.3491\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2004 - mse: 0.2004 - mae: 0.3409\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1940 - mse: 0.1940 - mae: 0.3342\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1870 - mse: 0.1870 - mae: 0.3264\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1811 - mse: 0.1811 - mae: 0.3223\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1761 - mse: 0.1761 - mae: 0.3175\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1716 - mse: 0.1716 - mae: 0.3138\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1666 - mse: 0.1666 - mae: 0.3082\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1633 - mse: 0.1633 - mae: 0.3047\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1592 - mse: 0.1592 - mae: 0.3023\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1562 - mse: 0.1562 - mae: 0.2976\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1530 - mse: 0.1530 - mae: 0.2934\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1505 - mse: 0.1505 - mae: 0.2927\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1477 - mse: 0.1477 - mae: 0.2880\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1447 - mse: 0.1447 - mae: 0.2842\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1429 - mse: 0.1429 - mae: 0.2833\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1408 - mse: 0.1408 - mae: 0.2797\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1383 - mse: 0.1383 - mae: 0.2774\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1366 - mse: 0.1366 - mae: 0.2751\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1358 - mse: 0.1358 - mae: 0.2746\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1340 - mse: 0.1340 - mae: 0.2737\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335 - mae: 0.2721\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1328 - mse: 0.1328 - mae: 0.2713\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1311 - mse: 0.1311 - mae: 0.2691\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1305 - mse: 0.1305 - mae: 0.2696\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1303 - mse: 0.1303 - mae: 0.2694\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1297 - mse: 0.1297 - mae: 0.2678\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1283 - mse: 0.1283 - mae: 0.2684\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1275 - mse: 0.1275 - mae: 0.2660\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1280 - mse: 0.1280 - mae: 0.2648\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1263 - mse: 0.1263 - mae: 0.2662\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1263 - mse: 0.1263 - mae: 0.2645\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1257 - mse: 0.1257 - mae: 0.2645\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1244 - mse: 0.1244 - mae: 0.2625\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1239 - mse: 0.1239 - mae: 0.2615\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1234 - mse: 0.1234 - mae: 0.2619\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1240 - mse: 0.1240 - mae: 0.2631\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1240 - mse: 0.1240 - mae: 0.2624\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1224 - mse: 0.1224 - mae: 0.2579\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1216 - mse: 0.1216 - mae: 0.2593\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1213 - mse: 0.1213 - mae: 0.2602\n"
     ]
    }
   ],
   "source": [
    "def create_seq_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining the input layer and first hidden layer\n",
    "    model.add(Dense(units=5, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the second layer of the model\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "    # The output neuron is a single fully connected node as only a single number is predicted\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    # Fitting the ANN to the training data\n",
    "    model.fit(X_train, y_train, batch_size=20, epochs=50, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "model_no = create_seq_model()\n",
    "model_no = train_model(model_no, X_train_no_trans, y_train_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "To find the best accuracy with the minimum number of layers/neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Mean Square Error (MSE) is used with the formula `(sum of all (y_true - y_pred)^2)/total number of y_true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Parameters: batch_size: 5 - Epochs: 5 MSE: 0.19724783797882628\n",
      "2 Parameters: batch_size: 5 - Epochs: 10 MSE: 0.1614009120629752\n",
      "3 Parameters: batch_size: 5 - Epochs: 50 MSE: 0.14135062407029314\n",
      "4 Parameters: batch_size: 5 - Epochs: 100 MSE: 0.11702383681250692\n",
      "5 Parameters: batch_size: 10 - Epochs: 5 MSE: 0.41614432148456304\n",
      "6 Parameters: batch_size: 10 - Epochs: 10 MSE: 0.20857683680317574\n",
      "7 Parameters: batch_size: 10 - Epochs: 50 MSE: 0.13570887727805733\n",
      "8 Parameters: batch_size: 10 - Epochs: 100 MSE: 0.13338939726211899\n",
      "9 Parameters: batch_size: 15 - Epochs: 5 MSE: 0.6951336186531647\n",
      "10 Parameters: batch_size: 15 - Epochs: 10 MSE: 0.2506945254710916\n",
      "11 Parameters: batch_size: 15 - Epochs: 50 MSE: 0.14543591651100338\n",
      "12 Parameters: batch_size: 15 - Epochs: 100 MSE: 0.13109650222121746\n",
      "13 Parameters: batch_size: 20 - Epochs: 5 MSE: 0.8193654647813673\n",
      "14 Parameters: batch_size: 20 - Epochs: 10 MSE: 0.5590260245581964\n",
      "15 Parameters: batch_size: 20 - Epochs: 50 MSE: 0.24236319308863344\n",
      "16 Parameters: batch_size: 20 - Epochs: 100 MSE: 0.1302349699938826\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters for ANN\n",
    "def find_best_params(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list = [5, 10, 15, 20]\n",
    "    epoch_list = [5, 10, 50, 100]\n",
    "\n",
    "    results = pd.DataFrame(columns=['trial_num', 'param', 'accuracy'])\n",
    "    \n",
    "    # Initialising the trials\n",
    "    trial_number = 0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            trial_number += 1\n",
    "            # Create ANN model\n",
    "            model = Sequential()\n",
    "\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Output neuron\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            MSE = 0\n",
    "            for i in range(y_test.shape[0]):\n",
    "                MSE += (y_test[i,0] - pred[i][0])**2\n",
    "\n",
    "            MSE /= y_test.shape[0]\n",
    "            \n",
    "            # Printing the results of the current iteration\n",
    "            print(trial_number, 'Parameters:','batch_size:', batch_size_trial,'-', 'Epochs:',epochs_trial, 'MSE:', MSE)\n",
    "            \n",
    "            results = results.append(pd.DataFrame(data=[[trial_number, str(batch_size_trial)+'-'+str(epochs_trial), MSE]], columns=['trial_num', 'param', 'mse'] ))\n",
    "\n",
    "    return(results)\n",
    "\n",
    "results_no = find_best_params(X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_bar_chart(results):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    colors = ['pink' if result != min(results['mse']) else 'purple' for result in results['mse']]\n",
    "    plt.bar(results['param'], height=results['mse'], color=colors)\n",
    "    # plt.axhline(y=1.0, color='purple', linestyle='-')\n",
    "    for a, b in zip([x for x in range(len(results['mse']))], round(results['mse'], 5)):\n",
    "        plt.text(a, b, str(b), color='black')\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_chart(results_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MSE, a lower value is better. From the graph above, it can be known that the best hyperparameters are `batch_size` = 5 and `epochs` = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_data):\n",
    "    # Sum of squared error\n",
    "    test_data['SE'] = (test_data['count'] - test_data['pred_count'])**2\n",
    "\n",
    "    print(test_data.head())\n",
    "\n",
    "    print(\"MSE: \", np.mean(test_data['SE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season      year     month  holiday   weekday   weather  temperature  \\\n",
      "0  0.449189  1.003466  0.147272 -0.16873 -1.505757 -0.736674     1.234309   \n",
      "1 -0.461798  1.003466 -0.439786 -0.16873  0.493847 -0.736674     0.533490   \n",
      "2  0.449189  1.003466  0.440802 -0.16873  0.993748  1.090784     1.475494   \n",
      "3 -0.461798  1.003466 -0.733315 -0.16873  0.993748 -0.736674    -0.504081   \n",
      "4  1.360175  1.003466  1.321389 -0.16873 -1.005856 -0.736674    -0.963703   \n",
      "\n",
      "   humidity  windspeed     count  pred_count        SE  \n",
      "0 -0.028125  -0.246866  1.095397    1.013958  0.006632  \n",
      "1 -0.761407   0.529099  1.506397    1.453898  0.002756  \n",
      "2  0.104396   0.349382  1.397250    0.849386  0.300155  \n",
      "3 -1.771513   1.460496  1.023851    0.445691  0.334268  \n",
      "4 -0.943989   0.619070  0.396644    0.265340  0.017241  \n",
      "MSE:  0.11213698541482214\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune hyperparameters\n",
    "def fine_tune_model(model, batch_size, epochs, X_scaler, y_scaler, X_train_trans, y_train_trans, X_test_trans, y_test_trans, columns):\n",
    "    model.fit(X_train_trans, y_train_trans, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "    pred = model.predict(X_test_trans)\n",
    "\n",
    "    test_data_scaled = pd.DataFrame(data=X_test_trans, columns=columns)\n",
    "    test_data_scaled['count'] = y_test_trans\n",
    "    test_data_scaled['pred_count'] = pred\n",
    "    evaluate_model(test_data_scaled)\n",
    "\n",
    "    # Scale predictions\n",
    "    pred = y_scaler.inverse_transform(pred)\n",
    "\n",
    "    # Scale back to original\n",
    "    y_test = y_scaler.inverse_transform(y_test_trans)\n",
    "    X_test = X_scaler.inverse_transform(X_test_trans)\n",
    "\n",
    "    test_data = pd.DataFrame(data=X_test, columns=columns)\n",
    "    test_data['count'] = y_test\n",
    "    test_data['pred_count'] = pred\n",
    "    # print(test_data.head())\n",
    "\n",
    "    return test_data\n",
    "\n",
    "test_data_no = fine_tune_model(\n",
    "        model=model_no,\n",
    "        batch_size=5,\n",
    "        epochs=100,\n",
    "        X_scaler=X_scaler_no,\n",
    "        y_scaler=y_scaler_no,\n",
    "        X_train_trans=X_train_no_trans,\n",
    "        y_train_trans=y_train_no_trans,\n",
    "        X_test_trans=X_test_no_trans,\n",
    "        y_test_trans=y_test_no_trans,\n",
    "        columns=X_test_no.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Data With Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584, 9) (584, 1) (147, 9) (147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_scaler_with, y_scaler_with, X_train_with_trans, y_train_with_trans, X_test_with_trans, y_test_with_trans = standardise_data(X_train_with, y_train_with, X_test_with, y_test_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 4ms/step - loss: 0.9980 - mse: 0.9980 - mae: 0.8152\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9853 - mse: 0.9853 - mae: 0.8102\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9332 - mse: 0.9332 - mae: 0.7887\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8111 - mse: 0.8111 - mae: 0.7342\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6383 - mse: 0.6383 - mae: 0.6483\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4765 - mse: 0.4765 - mae: 0.5558\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3510 - mse: 0.3510 - mae: 0.4678\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2772 - mse: 0.2772 - mae: 0.4090\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2372 - mse: 0.2372 - mae: 0.3719\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2183 - mse: 0.2183 - mae: 0.3547\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2064 - mse: 0.2064 - mae: 0.3443\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1972 - mse: 0.1972 - mae: 0.3373\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1907 - mse: 0.1907 - mae: 0.3310\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1837 - mse: 0.1837 - mae: 0.3253\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1776 - mse: 0.1776 - mae: 0.3199\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1712 - mse: 0.1712 - mae: 0.3132\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1658 - mse: 0.1658 - mae: 0.3082\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1612 - mse: 0.1612 - mae: 0.3037\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1565 - mse: 0.1565 - mae: 0.2985\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1541 - mse: 0.1541 - mae: 0.2951\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1500 - mse: 0.1500 - mae: 0.2919\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1473 - mse: 0.1473 - mae: 0.2906\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1453 - mse: 0.1453 - mae: 0.2853\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1423 - mse: 0.1423 - mae: 0.2832\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1407 - mse: 0.1407 - mae: 0.2831\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1388 - mse: 0.1388 - mae: 0.2789\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1376 - mse: 0.1376 - mae: 0.2773\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.1377 - mse: 0.1377 - mae: 0.2784\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1350 - mse: 0.1350 - mae: 0.2748\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1340 - mse: 0.1340 - mae: 0.2743\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335 - mae: 0.2718\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1321 - mse: 0.1321 - mae: 0.2724\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1314 - mse: 0.1314 - mae: 0.2703\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1318 - mse: 0.1318 - mae: 0.2679\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1303 - mse: 0.1303 - mae: 0.2710\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1300 - mse: 0.1300 - mae: 0.2684\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1294 - mse: 0.1294 - mae: 0.2696\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1283 - mse: 0.1283 - mae: 0.2666\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1278 - mse: 0.1278 - mae: 0.2652\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.1267 - mse: 0.1267 - mae: 0.2667\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1259 - mse: 0.1259 - mae: 0.2635\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1258 - mse: 0.1258 - mae: 0.2645\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1253 - mse: 0.1253 - mae: 0.2627\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1249 - mse: 0.1249 - mae: 0.2636\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1243 - mse: 0.1243 - mae: 0.2614\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1230 - mse: 0.1230 - mae: 0.2609\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1242 - mse: 0.1242 - mae: 0.2636\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1228 - mse: 0.1228 - mae: 0.2573\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.1225 - mae: 0.2616\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1213 - mse: 0.1213 - mae: 0.2556\n"
     ]
    }
   ],
   "source": [
    "model_with = create_seq_model()\n",
    "model_with = train_model(model_with, X_train_with_trans, y_train_with_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same `batch_size` and `epochs` are used for accuracy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season      year     month   holiday   weekday   weather  temperature  \\\n",
      "0  0.441688 -0.993174  0.131722 -0.167836  1.508537 -0.720359     1.060122   \n",
      "1  0.441688 -0.993174  0.131722 -0.167836  0.502271 -0.720359     1.404064   \n",
      "2 -1.362130 -0.993174 -1.603446 -0.167836  1.508537  1.141100    -1.401794   \n",
      "3 -1.362130 -0.993174 -1.314251 -0.167836 -0.503995  1.141100    -1.625316   \n",
      "4 -1.362130  1.006873 -1.603446 -0.167836  0.502271  1.141100    -0.813466   \n",
      "\n",
      "   humidity  windspeed     count  pred_count        SE  \n",
      "0 -0.276179   0.246691  0.750388    0.249310  0.251079  \n",
      "1  0.196746  -0.396460  0.050831    0.154996  0.010850  \n",
      "2 -0.891873  -0.412649 -1.706735   -1.418742  0.082939  \n",
      "3  1.469644  -1.783575 -1.647869   -1.753354  0.011127  \n",
      "4  1.041464  -1.519431 -0.220898   -0.283682  0.003942  \n",
      "MSE:  0.14570633455464452\n"
     ]
    }
   ],
   "source": [
    "test_data_with = fine_tune_model(\n",
    "    model=model_with,\n",
    "    batch_size=15,\n",
    "    epochs=10,\n",
    "    X_scaler=X_scaler_with,\n",
    "    y_scaler=y_scaler_with,\n",
    "    X_train_trans=X_train_with_trans,\n",
    "    y_train_trans=y_train_with_trans,\n",
    "    X_test_trans=X_test_with_trans,\n",
    "    y_test_trans=y_test_with_trans,\n",
    "    columns=X_test_with.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, using cleaned data without outliers would give a higher accuracy than using data with outliers."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
