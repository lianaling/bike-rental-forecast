{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Artificial Neural Networks for Regression\n",
    "\n",
    "_By: Ling Li Ya, Liana_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.1 Pre-training preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/liana/.local/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/liana/.local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (59.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/liana/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/liana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/liana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/liana/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/liana/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: keras in /home/liana/.local/lib/python3.8/site-packages (2.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 13:34:34.534224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-02 13:34:34.534546: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned dataset with no outliers\n",
    "X_train_no = pd.read_csv('../dataset/no_outliers/X_train.csv')\n",
    "X_test_no = pd.read_csv('../dataset/no_outliers/X_test.csv')\n",
    "y_train_no = pd.read_csv('../dataset/no_outliers/y_train.csv')\n",
    "y_test_no = pd.read_csv('../dataset/no_outliers/y_test.csv')\n",
    "\n",
    "# Uncleaned original data\n",
    "X_train_with = pd.read_csv('../dataset/with_outliers/X_train.csv')\n",
    "X_test_with = pd.read_csv('../dataset/with_outliers/X_test.csv')\n",
    "y_train_with = pd.read_csv('../dataset/with_outliers/y_train.csv')\n",
    "y_test_with = pd.read_csv('../dataset/with_outliers/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standardise_data(X_train, y_train, X_test, y_test):\n",
    "    # X_scaler = StandardScaler()\n",
    "    # y_scaler = StandardScaler()\n",
    "\n",
    "    # # Scale data to standardise data values\n",
    "    # X_train_trans = X_scaler.fit_transform(X_train)\n",
    "    # y_train_trans = y_scaler.fit_transform(y_train)\n",
    "    # X_test_trans = X_scaler.transform(X_test)\n",
    "    # y_test_trans = y_scaler.transform(y_test)\n",
    "    \n",
    "    # print(X_train_trans.shape, y_train_trans.shape, X_test_trans.shape, y_test_trans.shape)\n",
    "\n",
    "    # return X_scaler, y_scaler, X_train_trans, y_train_trans, X_test_trans, y_test_trans\n",
    "    # return X_scaler, y_scaler, X_train, y_train, X_test, y_test\n",
    "\n",
    "# X_scaler_no, y_scaler_no, X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans = standardise_data(X_train_no, y_train_no, X_test_no, y_test_no)\n",
    "X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans = X_train_no.to_numpy(), y_train_no.to_numpy(), X_test_no.to_numpy(), y_test_no.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.2 Training\n",
    "\n",
    "Using a layer with 5 neurons, with 9 input dimensions of normal weight, using relu activation function. Batch size is 20 and training epochs are 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 13:34:37.028880: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2021-12-02 13:34:37.028960: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Liana-ASUS): /proc/driver/nvidia/version does not exist\n",
      "2021-12-02 13:34:37.029639: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3079 - mse: 0.3079 - mae: 0.5074\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2586 - mse: 0.2586 - mae: 0.4568\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1718 - mse: 0.1718 - mae: 0.3576\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2283\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 910us/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1627\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 968us/step - loss: 0.0379 - mse: 0.0379 - mae: 0.1572\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 915us/step - loss: 0.0358 - mse: 0.0358 - mae: 0.1530\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 896us/step - loss: 0.0325 - mse: 0.0325 - mae: 0.1457\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 857us/step - loss: 0.0272 - mse: 0.0272 - mae: 0.1331\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1180\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 860us/step - loss: 0.0173 - mse: 0.0173 - mae: 0.1041\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 936us/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0953\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0901\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 982us/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0869\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0844\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0826\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0816\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0803\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0800\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0794\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0786\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 994us/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0786\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0784\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0777\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0779\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0767\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 941us/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0782\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 895us/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0776\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 901us/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0774\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 866us/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0773\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0777\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0780\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 944us/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0775\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0775\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 987us/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0765\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 966us/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0775\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0770\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0769\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0763\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 920us/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0761\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0758\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 988us/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0758\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0745\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0749\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 957us/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0741\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 925us/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0740\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 835us/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0730\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 988us/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0735\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0726\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0734\n"
     ]
    }
   ],
   "source": [
    "def create_seq_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining the input layer and first hidden layer\n",
    "    model.add(Dense(units=5, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the second layer of the model\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "    # The output neuron is a single fully connected node as only a single number is predicted\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    # Fitting the ANN to the training data\n",
    "    model.fit(X_train, y_train, batch_size=20, epochs=50, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "model_no = create_seq_model()\n",
    "model_no = train_model(model_no, X_train_no_trans, y_train_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using data with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaler_with, y_scaler_with, X_train_with_trans, y_train_with_trans, X_test_with_trans, y_test_with_trans = standardise_data(X_train_with, y_train_with, X_test_with, y_test_with)\n",
    "X_train_with_trans, y_train_with_trans, X_test_with_trans, y_test_with_trans = X_train_with.to_numpy(), y_train_with.to_numpy(), X_test_with.to_numpy(), y_test_with.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 0s 877us/step - loss: 0.3033 - mse: 0.3033 - mae: 0.5040\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 922us/step - loss: 0.2443 - mse: 0.2443 - mae: 0.4427\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 856us/step - loss: 0.1558 - mse: 0.1558 - mae: 0.3383\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 811us/step - loss: 0.0679 - mse: 0.0679 - mae: 0.2137\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 878us/step - loss: 0.0377 - mse: 0.0377 - mae: 0.1579\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 901us/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1527\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 796us/step - loss: 0.0332 - mse: 0.0332 - mae: 0.1478\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 815us/step - loss: 0.0296 - mse: 0.0296 - mae: 0.1391\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 828us/step - loss: 0.0253 - mse: 0.0253 - mae: 0.1286\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 806us/step - loss: 0.0212 - mse: 0.0212 - mae: 0.1173\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 833us/step - loss: 0.0179 - mse: 0.0179 - mae: 0.1056\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 874us/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0970\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 972us/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0918\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 848us/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0883\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 883us/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0857\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 817us/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0841\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 840us/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0823\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 901us/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0807\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0794\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0787\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0776\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 820us/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0778\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 806us/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0769\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 957us/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0758\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0777\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 999us/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0761\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 848us/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0763\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 878us/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0748\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 839us/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0749\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 797us/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0749\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 876us/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0743\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 828us/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0742\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 824us/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0750\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 845us/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0744\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 903us/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0742\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 814us/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0743\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 815us/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0746\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 851us/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0738\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 820us/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0737\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 813us/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0738\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 825us/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0737\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 802us/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0734\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 825us/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0727\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 863us/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0726\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 809us/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0725\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 883us/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0725\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 863us/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0715\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 803us/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0712\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 822us/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0701\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 861us/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0700\n"
     ]
    }
   ],
   "source": [
    "model_with = create_seq_model()\n",
    "model_with = train_model(model_with, X_train_with_trans, y_train_with_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.3 Hyperparameter tuning\n",
    "\n",
    "To find the best accuracy with the minimum number of layers/neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "Mean Square Error (MSE) is used with the formula `(sum of all (y_true - y_pred)^2)/total number of y_true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1 Parameters: batch_size: 5 - Epochs: 5 MSE: 0.017635188410956966\n",
      "2 Parameters: batch_size: 5 - Epochs: 10 MSE: 0.01403044278123201\n",
      "3 Parameters: batch_size: 5 - Epochs: 50 MSE: 0.008130271051181017\n",
      "4 Parameters: batch_size: 5 - Epochs: 100 MSE: 0.007804983862675252\n",
      "5 Parameters: batch_size: 10 - Epochs: 5 MSE: 0.032442627737033325\n",
      "6 Parameters: batch_size: 10 - Epochs: 10 MSE: 0.015060443617070094\n",
      "7 Parameters: batch_size: 10 - Epochs: 50 MSE: 0.00837337365383405\n",
      "8 Parameters: batch_size: 10 - Epochs: 100 MSE: 0.010940945560182455\n",
      "9 Parameters: batch_size: 15 - Epochs: 5 MSE: 0.041065336039560855\n",
      "10 Parameters: batch_size: 15 - Epochs: 10 MSE: 0.020831606351105397\n",
      "11 Parameters: batch_size: 15 - Epochs: 50 MSE: 0.008410321237324514\n",
      "12 Parameters: batch_size: 15 - Epochs: 100 MSE: 0.010834147090105151\n",
      "13 Parameters: batch_size: 20 - Epochs: 5 MSE: 0.04697578592542259\n",
      "14 Parameters: batch_size: 20 - Epochs: 10 MSE: 0.026136945057218794\n",
      "15 Parameters: batch_size: 20 - Epochs: 50 MSE: 0.010574378350527106\n",
      "16 Parameters: batch_size: 20 - Epochs: 100 MSE: 0.010815566676418009\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters for ANN\n",
    "def find_best_params(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    print(type(y_test))\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list = [5, 10, 15, 20]\n",
    "    epoch_list = [5, 10, 50, 100]\n",
    "\n",
    "    results = pd.DataFrame(columns=['trial_num', 'param', 'accuracy'])\n",
    "    \n",
    "    # Initialising the trials\n",
    "    trial_number = 0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            trial_number += 1\n",
    "            # Create ANN model\n",
    "            model = Sequential()\n",
    "\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Output neuron\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            MSE = 0\n",
    "            for i in range(y_test.shape[0]):\n",
    "                MSE += (y_test[i,0] - pred[i][0])**2\n",
    "\n",
    "            MSE /= y_test.shape[0]\n",
    "            \n",
    "            # Printing the results of the current iteration\n",
    "            print(trial_number, 'Parameters:','batch_size:', batch_size_trial,'-', 'Epochs:',epochs_trial, 'MSE:', MSE)\n",
    "            \n",
    "            results = results.append(pd.DataFrame(data=[[trial_number, str(batch_size_trial)+'-'+str(epochs_trial), MSE]], columns=['trial_num', 'param', 'mse'] ))\n",
    "\n",
    "    return(results)\n",
    "\n",
    "results_no = find_best_params(X_train_no_trans, y_train_no_trans, X_test_no_trans, y_test_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_bar_chart(results):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    colors = ['pink' if result != min(results['mse']) else 'purple' for result in results['mse']]\n",
    "    plt.bar(results['param'], height=results['mse'], color=colors)\n",
    "    # plt.axhline(y=1.0, color='purple', linestyle='-')\n",
    "    for a, b in zip([x for x in range(len(results['mse']))], round(results['mse'], 5)):\n",
    "        plt.text(a, b, str(b), color='black')\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_chart(results_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MSE, a lower value is better. From the graph above, it can be known that the best hyperparameters are `batch_size` = 5 and `epochs` = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_data):\n",
    "    # Sum of squared error\n",
    "    test_data['SE'] = (test_data['count'] - test_data['pred_count'])**2\n",
    "    r2 = r2_score(test_data['count'], test_data['pred_count'])\n",
    "\n",
    "    print(test_data.head())\n",
    "\n",
    "    print(\"r2: \", r2)\n",
    "    print(\"MSE: \", np.mean(test_data['SE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.4 Fine-tuning and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season  year     month  holiday   weekday  weather  temperature  \\\n",
      "0  0.666667   1.0  0.545455      0.0  0.000000      0.0     0.838615   \n",
      "1  0.333333   1.0  0.363636      0.0  0.666667      0.0     0.676174   \n",
      "2  0.666667   1.0  0.636364      0.0  0.833333      0.5     0.894519   \n",
      "3  0.333333   1.0  0.272727      0.0  0.833333      0.0     0.435679   \n",
      "4  1.000000   1.0  0.909091      0.0  0.166667      0.0     0.329145   \n",
      "\n",
      "   humidity  windspeed     count  pred_count        SE  \n",
      "0  0.499402   0.337110  0.770538    0.808525  0.001443  \n",
      "1  0.350479   0.492593  0.862768    0.818375  0.001971  \n",
      "2  0.526316   0.456582  0.838275    0.790218  0.002309  \n",
      "3  0.145335   0.679220  0.754483    0.648287  0.011277  \n",
      "4  0.313398   0.510620  0.613735    0.593400  0.000413  \n",
      "r2:  0.8610889177637269\n",
      "MSE:  0.007985720980195267\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune hyperparameters\n",
    "# def fine_tune_model(model, batch_size, epochs, X_scaler, y_scaler, X_train_trans, y_train_trans, X_test_trans, y_test_trans, columns):\n",
    "def fine_tune_model(model, batch_size, epochs, X_train_trans, y_train_trans, X_test_trans, y_test_trans, columns):\n",
    "    model.fit(X_train_trans, y_train_trans, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "    pred = model.predict(X_test_trans)\n",
    "\n",
    "    test_data_scaled = pd.DataFrame(data=X_test_trans, columns=columns)\n",
    "    test_data_scaled['count'] = y_test_trans\n",
    "    test_data_scaled['pred_count'] = pred\n",
    "    evaluate_model(test_data_scaled)\n",
    "    return test_data_scaled\n",
    "\n",
    "test_data_no = fine_tune_model(\n",
    "        model=model_no,\n",
    "        batch_size=5,\n",
    "        epochs=100,\n",
    "        # X_scaler=X_scaler_no,\n",
    "        # y_scaler=y_scaler_no,\n",
    "        X_train_trans=X_train_no_trans,\n",
    "        y_train_trans=y_train_no_trans,\n",
    "        X_test_trans=X_test_no_trans,\n",
    "        y_test_trans=y_test_no_trans,\n",
    "        columns=X_test_no.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Data With Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same `batch_size` and `epochs` are used for accuracy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     season  year     month  holiday   weekday  weather  temperature  \\\n",
      "0  0.666667   0.0  0.545455      0.0  1.000000      0.0     0.794313   \n",
      "1  0.666667   0.0  0.545455      0.0  0.666667      0.0     0.874478   \n",
      "2  0.000000   0.0  0.000000      0.0  1.000000      0.5     0.220499   \n",
      "3  0.000000   0.0  0.090909      0.0  0.333333      0.5     0.168402   \n",
      "4  0.000000   1.0  0.000000      0.0  0.666667      0.5     0.357625   \n",
      "\n",
      "   humidity  windspeed     count  pred_count        SE  \n",
      "0  0.443780   0.436975  0.691550    0.562434  0.016671  \n",
      "1  0.538876   0.307644  0.535568    0.540551  0.000025  \n",
      "2  0.319976   0.304389  0.143677    0.201897  0.003389  \n",
      "3  0.794830   0.028710  0.156803    0.123195  0.001129  \n",
      "4  0.708732   0.081826  0.474979    0.430659  0.001964  \n",
      "r2:  0.8544147523979604\n",
      "MSE:  0.008504011624982854\n"
     ]
    }
   ],
   "source": [
    "test_data_with = fine_tune_model(\n",
    "    model=model_with,\n",
    "    batch_size=5,\n",
    "    epochs=100,\n",
    "    X_train_trans=X_train_with_trans,\n",
    "    y_train_trans=y_train_with_trans,\n",
    "    X_test_trans=X_test_with_trans,\n",
    "    y_test_trans=y_test_with_trans,\n",
    "    columns=X_test_with.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, using cleaned data without outliers would give a higher accuracy than using data with outliers."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
